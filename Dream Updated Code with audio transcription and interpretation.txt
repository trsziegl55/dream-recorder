// Variables to hold the recorder and the audio blob
let recorder;
let audioBlob;
let audioUrl;
let audio;
let transcriptionText = "";
let apiKey = "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"; // Replace with your actual OpenAI API Key
let apiEndpoint = "https://api.openai.com/v1/completions"; // OpenAI API endpoint for completions

// Record the dream using the microphone
document.getElementById("recordButton").addEventListener("click", () => {
    navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
        recorder = new RecordRTC(stream, { type: 'audio' });
        recorder.startRecording();
        document.getElementById("recordButton").disabled = true;
        document.getElementById("stopButton").disabled = false;
        document.getElementById("downloadButton").disabled = true;
        document.getElementById("transcribeButton").disabled = true;
    }).catch((err) => {
        console.log("Error accessing microphone: ", err);
    });
});

// Stop recording and enable the transcription and download buttons
document.getElementById("stopButton").addEventListener("click", () => {
    recorder.stopRecording(() => {
        audioBlob = recorder.getBlob();
        audioUrl = URL.createObjectURL(audioBlob);
        audio = new Audio(audioUrl);
        document.getElementById("stopButton").disabled = true;
        document.getElementById("downloadButton").disabled = false;
        document.getElementById("transcribeButton").disabled = false;
    });
});

// Download the recording
document.getElementById("downloadButton").addEventListener("click", () => {
    const link = document.createElement('a');
    link.href = audioUrl;
    link.download = 'dream-recording.wav';
    link.click();
});

// Transcribe the recording to text
document.getElementById("transcribeButton").addEventListener("click", () => {
    transcribeAudio(audioBlob).then((transcription) => {
        transcriptionText = transcription;
        document.getElementById("transcription").textContent = transcription;
        document.getElementById("interpretButton").disabled = false;
    });
});

// Interpret the dream using OpenAI API
document.getElementById("interpretButton").addEventListener("click", () => {
    interpretDream(transcriptionText).then((interpretation) => {
        document.getElementById("interpretation").textContent = interpretation;
    });
});

// Function to transcribe the audio to text using the Google Cloud Speech-to-Text API
async function transcribeAudio(audioBlob) {
    const formData = new FormData();
    formData.append("file", audioBlob, "audio.wav");
    
    const response = await fetch('https://your-transcription-api-endpoint.com/transcribe', {
        method: 'POST',
        body: formData
    });

    const data = await response.json();
    return data.transcription; // Assuming the API response includes a 'transcription' field
}

// Function to interpret the dream using OpenAI API
async function interpretDream(dreamText) {
    const response = await fetch(apiEndpoint, {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            model: "text-davinci-003", // Replace with the latest OpenAI model if needed
            prompt: `Interpret this dream: ${dreamText}`,
            max_tokens: 150
        })
    });

    const data = await response.json();
    return data.choices[0].text.trim();
}















